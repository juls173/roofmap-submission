{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c230a478-d35b-466b-88c7-7498fcb7ab97",
   "metadata": {},
   "source": [
    "#### Project Description\n",
    "\n",
    "Solar energy plays a crucial role in reducing greenhouse gas emissions and meeting rising energy demands. Information on building roof types and geometry is essential for assessing solar potential, improving energy efficiency, and supporting energy transition policies. Roof material and shape data also can inform studies on thermal efficiency, roof durability, disaster risk, heritage conservation, urban heat, and more.\n",
    "\n",
    "This study aims to develop two ready-to-use, AI-ready open datasets containing both building roof types and geometry, along with a scalable pipeline for roof material classification. The dataset is created using OpenStreetMap (OSM) roof material labels and high-resolution satellite imagery obtained from [OpenAerialMap](https://map.openaerialmap.org/#/7.164459228515626,50.84562199133437,12/square/12020303222/617970f8800b10000509eda7?_k=h73n1n), originally from the Maxar [Open Data Program](https://www.maxar.com/open-data), leveraging OSM building outlines to avoid computationally expensive segmentation processes. This notebook includes the code to obtain and preprocess this data, which can be used to transform any geospatial dataset into the YOLO dataset format, in addition to training a model.\n",
    "\n",
    "To demonstrate the dataset’s applicability, a convolutional neural network (CNN) model, specifically, Ultralytics' YOLOv11, is used to classify roofs into categories such as roof tiles, tar paper, and metal, followed by an evaluation of the model’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660e1cf-5002-4b7c-8487-e80bae9aba49",
   "metadata": {},
   "source": [
    "#### Step 0: Ensure dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b640725-cf30-4d38-acc6-7ad26e2d7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fbb9e9-e580-4467-a482-269599fdb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib as plt\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from shapely.geometry import box, Polygon\n",
    "import cv2\n",
    "import overpy\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f77d2-a7a6-46ee-a98c-8f9e928a722d",
   "metadata": {},
   "source": [
    "#### Step 1: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc6163-fbaf-4f9d-954e-6925880eb023",
   "metadata": {},
   "source": [
    "First, we query all the roofs that have a roof:material OpenStreetMap(OSM) tag in the study area. We will be using the Overpass API, which allows us to fetch data from OSM. More information about the Overpass API query language and other examples can be found here: https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_API_by_Example.\n",
    "\n",
    "We recommend using taginfo's regional databases to get a better understanding of where OpenStreetMap Data you are looking for exists https://taginfo.geofabrik.de/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21103ddf-4c0b-45a7-b3d9-a6e3c80d2d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total buildings queried: 543\n",
      "first 4 buildings: [{'id': 77644686, 'roof_material': 'roof_tiles', 'geometry': [(7.1014851, 50.8568545), (7.101623, 50.8568603), (7.1016302, 50.8568606), (7.1016321, 50.8568421), (7.1016359, 50.8568062), (7.1014702, 50.8567992), (7.1014645, 50.8568536), (7.1014851, 50.8568545)]}, {'id': 77644695, 'roof_material': 'roof_tiles', 'geometry': [(7.1019162, 50.8559073), (7.1019143, 50.8559339), (7.1019084, 50.8560152), (7.1020193, 50.8560183), (7.1021328, 50.8560216), (7.1021406, 50.8559137), (7.1019162, 50.8559073)]}, {'id': 77644703, 'roof_material': 'roof_tiles', 'geometry': [(7.1023742, 50.8562211), (7.1023659, 50.8563396), (7.1025967, 50.856346), (7.1026031, 50.8562539), (7.1026049, 50.8562275), (7.1023742, 50.8562211)]}]\n"
     ]
    }
   ],
   "source": [
    "import overpy\n",
    "\n",
    "def query_osm(bbox: tuple[float, float, float, float]) -> list[dict[str, int|str|list[tuple[float, float]]]]:\n",
    "    \"\"\"\n",
    "    Queries OpenStreetMap (OSM) using Overpass API for buildings within a given bounding box\n",
    "    that have roof material data.\n",
    "\n",
    "    Args:\n",
    "        bbox (tuple[float, float, float, float]): Bounding box coordinates in the format \n",
    "            (min_latitude, min_longitude, max_latitude, max_longitude).\n",
    "\n",
    "    Returns:\n",
    "        list[dict[str, int | str | list[tuple[float, float]]]]: A list of dictionaries where each dictionary represents a building.\n",
    "            Each dictionary contains:\n",
    "            - \"id\" (int): OSM way ID.\n",
    "            - \"roof_material\" (str): Roof material type or \"unknown\" if not specified.\n",
    "            - \"geometry\" (list[tuple[float, float]]): List of (longitude, latitude) tuples \n",
    "              representing the building's outline.\n",
    "    \"\"\"\n",
    "    api = overpy.Overpass()\n",
    "    query = f\"\"\"\n",
    "[out:json][timeout:180];\n",
    "(\n",
    "way[\"building\"][\"roof:material\"]{bbox};\n",
    ");\n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "\"\"\"\n",
    "\n",
    "    response = api.query(query)\n",
    "\n",
    "    bldgs = []\n",
    "    for way in response.ways:\n",
    "        building = {\n",
    "        \"id\": way.id,\n",
    "        \"roof_material\": way.tags.get(\"roof:material\", \"unknown\"),\n",
    "        \"geometry\": [(float(node.lon), float(node.lat)) for node in way.nodes]\n",
    "        #shapely expects longitude, latitude, in addition to GeoJSONs, even though WGS894 uses latitude, longitude\n",
    "    }\n",
    "        bldgs.append(building)\n",
    "    return bldgs\n",
    "\n",
    "# change the bounding box coordinates to get data from your desired study area (min latitude, min longitude, max latitude, max longitude)\n",
    "bbox = (50.8528358718, 7.09837786378, 50.8568310836, 7.1090734608)\n",
    "# Cologne: 49.97138, 6.69497, 51.02720390596486, 6.907890818310556\n",
    "# Bonn: 50.47044, 7.04552, 50.917936, 7.271421\n",
    "# Meckenheim: 50.13682, 6.90614, 50.5464, 7.0739\n",
    "# Sample: 50.8528358718, 7.0983778637, 50.8568310836, 7.1090734608\n",
    "buildings_material = query_osm(bbox)\n",
    "\n",
    "print(f\"total buildings queried: {len(buildings_material)}\")\n",
    "print(f\"first 4 buildings: {buildings_material[0:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fea958-4860-4f2a-b612-bd926782138d",
   "metadata": {},
   "source": [
    "Next, we convert the queried OSM data into a usable GeoJSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb6dfaa-b4da-4e28-bada-83674619c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roof_material\n",
      "roof_tiles    435\n",
      "tar_paper     102\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_building_material_gdf(buildings):\n",
    "    \"\"\"\n",
    "    Creates a GeoDataFrame from a list of building data, standardizes roof material labels,\n",
    "    filters out rare categories, and saves the data as GeoJSON files.\n",
    "\n",
    "    Args:\n",
    "        buildings (list[dict[str, int | str | list[tuple[float, float]]]]): A list of dictionaries representing buildings,\n",
    "            each containing:\n",
    "            - \"id\" (int): The OSM way ID.\n",
    "            - \"roof_material\" (str): The type of roof material.\n",
    "            - \"geometry\" (list[tuple[float, float]]): List of (longitude, latitude) tuples.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Filtered GeoDataFrame containing buildings with more common roof materials.\n",
    "    \"\"\"\n",
    "    geometries = [Polygon(building[\"geometry\"]) for building in buildings]\n",
    "    roof_materials = [building[\"roof_material\"] for building in buildings]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame({\"roof_material\": roof_materials}, geometry=geometries)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    # filter roof categories to ensure \n",
    "    category_counts = gdf[\"roof_material\"].value_counts()\n",
    "    keep_materials = category_counts[category_counts > 10].index.tolist()\n",
    "    gdf_filtered = gdf[gdf['roof_material'].isin(keep_materials)]\n",
    "\n",
    "    output_file = \"sample_buildings.geojson\"\n",
    "    gdf.to_file(output_file, driver=\"GeoJSON\")\n",
    "\n",
    "    output_file_filtered = \"sample_buildings_filtered.geojson\"\n",
    "    gdf_filtered.to_file(output_file_filtered, driver=\"GeoJSON\")\n",
    "    return gdf_filtered\n",
    "\n",
    "gdf_filtered = create_building_material_gdf(buildings_material)\n",
    "print(gdf_filtered['roof_material'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6686cc5-68dd-4d0d-8aff-486875a9aaf8",
   "metadata": {},
   "source": [
    "#### Step 2: Data Preprocessing and Formatting\n",
    "In this step, we use the RoofMaterialDatasetConverter class to prepare our dataset for training a YOLO model. This involves slicing the input raster image into overlapping patches and generating corresponding label files based on the roof material polygons from the GeoJSON. Each patch is filtered to ensure it contains a minimum number of labeled buildings. For valid patches, the building footprints are clipped, normalized, and saved in YOLO segmentation format. The dataset is then automatically split into training, validation, and test sets, and saved in a structured format. A YAML configuration file is also created to define the dataset structure and class labels for use during model training.\n",
    "\n",
    "Note that the sample dataset is extremely unbalanced and does not include the other 4 notable roof classes. After saving the queried OpenStreetMap data to a GeoJSON, we manually aligned the data and fixed incorrect labels in QGIS. For the purpose of the sample dataset demonstration, we will use the GeoJSON that was just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d712e136-4687-43c1-a977-02e17842b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoofMaterialDatasetConverter:\n",
    "    def __init__(self, \n",
    "                 geojson_path: str, \n",
    "                 raster_path: str, \n",
    "                 output_dir: str, \n",
    "                 patch_size: int = 640, \n",
    "                 overlap: int = 128,\n",
    "                 patch_min_buildings: int = 2) -> None:\n",
    "\n",
    "        self.gdf = gpd.read_file(geojson_path)\n",
    "        self.raster = rasterio.open(raster_path)\n",
    "        \n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(output_dir, 'images', split), exist_ok=True)\n",
    "            os.makedirs(os.path.join(output_dir, 'labels', split), exist_ok=True)\n",
    "        \n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.patch_min_buildings = patch_min_buildings\n",
    "\n",
    "        self.class_mapping = {\n",
    "            'roof_tiles': 0,\n",
    "            'tar_paper': 1,\n",
    "            'metal': 2,\n",
    "            'concrete': 3,\n",
    "            'tile': 4,\n",
    "            'gravel': 5,\n",
    "            'glass': 6\n",
    "        }\n",
    "\n",
    "    def generate_patches(self, \n",
    "                     train_ratio: float = 0.7, \n",
    "                     val_ratio: float = 0.15, \n",
    "                     random_state: int = 42) -> dict[str, list[tuple[str, str]]]:\n",
    "        \"\"\"\n",
    "        Generate image patches with corresponding roof material labels.\n",
    "        \n",
    "        Returns:\n",
    "            list of tuples: [(image_path, label_path), ...]\n",
    "        \"\"\"\n",
    "        rng = np.random.default_rng(random_state)\n",
    "\n",
    "        # collect all potential patches\n",
    "        all_patches: list[tuple[str, str]] = []\n",
    "        \n",
    "        height, width = self.raster.height, self.raster.width\n",
    "        for y in range(0, height, self.patch_size - self.overlap):\n",
    "            for x in range(0, width, self.patch_size - self.overlap):\n",
    "                window = Window(x, y, self.patch_size, self.patch_size)\n",
    "                \n",
    "                # read patch from raster\n",
    "                try:\n",
    "                    patch = self.raster.read(window=window)\n",
    "                    patch = np.transpose(patch[:3], (1, 2, 0))  # transpose to HWC\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping patch at ({x},{y}) due to error: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # check if patch contains any roof material labels\n",
    "                patch_bounds = box(\n",
    "                    self.raster.xy(y, x)[0], \n",
    "                    self.raster.xy(y, x)[1],\n",
    "                    self.raster.xy(y + self.patch_size, x + self.patch_size)[0],\n",
    "                    self.raster.xy(y + self.patch_size, x + self.patch_size)[1]\n",
    "                )\n",
    "                \n",
    "                # filter roof polygons within this patch\n",
    "                patch_roofs = self.gdf[self.gdf.intersects(patch_bounds)]\n",
    "                \n",
    "                if len(patch_roofs) >= self.patch_min_buildings:\n",
    "                    label_content = self._generate_labels(patch_roofs, patch_bounds)\n",
    "                    if label_content:\n",
    "                        all_patches.append((patch, (y, x), label_content))\n",
    "        \n",
    "        # randomly split patches\n",
    "        n_patches = len(all_patches)\n",
    "        train_size = int(n_patches * train_ratio)\n",
    "        val_size = int(n_patches * val_ratio)\n",
    "        \n",
    "        rng.shuffle(all_patches)\n",
    "        \n",
    "        train_patches = all_patches[:train_size]\n",
    "        val_patches = all_patches[train_size:train_size+val_size]\n",
    "        test_patches = all_patches[train_size+val_size:]\n",
    "        \n",
    "        split_paths = {\n",
    "            'train': [],\n",
    "            'val': [],\n",
    "            'test': []\n",
    "        }\n",
    "        \n",
    "        for split, patches in [('train', train_patches), ('val', val_patches), ('test', test_patches)]:\n",
    "            for patch, (y, x), label_content in patches:\n",
    "                patch_filename = f'patch_{y}_{x}.png'\n",
    "                \n",
    "                img_path = os.path.join(self.output_dir, 'images', split, patch_filename)\n",
    "                label_path = os.path.join(self.output_dir, 'labels', split, patch_filename.replace('.png', '.txt'))\n",
    "                \n",
    "                os.makedirs(os.path.dirname(img_path), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(label_path), exist_ok=True)\n",
    "                \n",
    "                cv2.imwrite(img_path, cv2.cvtColor(patch, cv2.COLOR_RGB2BGR))\n",
    "                \n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(label_content))\n",
    "                split_paths[split].append((img_path, label_path))\n",
    "        \n",
    "        return split_paths\n",
    "\n",
    "    def _generate_labels(self, \n",
    "                         roof_polygons: gpd.GeoDataFrame,\n",
    "                         patch_bounds: box) -> list[str]:\n",
    "        \"\"\"\n",
    "        Generate YOLO segmentation labels for roof polygons in a patch.\n",
    "        \n",
    "        Parameters:\n",
    "            roof_polygons : GeoDataFrame\n",
    "                GeoDataFrame of roof polygons in the current patch\n",
    "            patch_bounds : shapely.geometry.box\n",
    "                Bounding box of the current patch\n",
    "        \n",
    "        Returns:\n",
    "            list of label strings\n",
    "        \"\"\"\n",
    "        labels: list[str] = []\n",
    "        \n",
    "        for _, roof in roof_polygons.iterrows():\n",
    "            # only include specified roof material classes\n",
    "            class_name = roof['roof_material']\n",
    "            if class_name not in self.class_mapping:\n",
    "                continue\n",
    "            class_index = self.class_mapping[class_name]\n",
    "            \n",
    "            # clip polygon to patch bounds\n",
    "            clipped_roof = roof.geometry.intersection(patch_bounds)\n",
    "            \n",
    "            if not clipped_roof.is_empty:\n",
    "                try:\n",
    "                    coords = np.array(clipped_roof.exterior.coords)\n",
    "                    normalized_coords = self._normalize_coordinates(coords, patch_bounds)\n",
    "                    \n",
    "                    if len(normalized_coords) >= 3:\n",
    "                        # create label string: class_index x1 y1 x2 y2 ...\n",
    "                        label = f\"{class_index} \" + \" \".join(map(str, normalized_coords.flatten()))\n",
    "                        labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing roof polygon: {e}\")\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def _normalize_coordinates(self, \n",
    "                               coords: np.ndarray, \n",
    "                               patch_bounds: box) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Normalize polygon coordinates to 0-1 range within patch.\n",
    "        \n",
    "        Parameters:\n",
    "            coords: numpy.ndarray\n",
    "                Original polygon coordinates\n",
    "            patch_bounds : shapely.geometry.box\n",
    "                Bounding box of the current patch\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray of normalized coordinates\n",
    "        \"\"\"\n",
    "        x_min, y_min = patch_bounds.bounds[0], patch_bounds.bounds[1]\n",
    "        x_max, y_max = patch_bounds.bounds[2], patch_bounds.bounds[3]\n",
    "        normalized_coords = coords.copy()\n",
    "        normalized_coords[:, 0] = (coords[:, 0] - x_min) / (x_max - x_min)\n",
    "        #normalized_coords[:, 1] = (coords[:, 1] - y_min) / (y_max - y_min)\n",
    "        normalized_coords[:, 1] = (y_max - coords[:, 1]) / (y_max - y_min)\n",
    "\n",
    "        return normalized_coords\n",
    "    \n",
    "    def create_dataset_yaml(self) -> str:\n",
    "        \"\"\"\n",
    "        Create YOLO dataset configuration YAML file.\n",
    "        \n",
    "        Returns:\n",
    "            str: Path to the created YAML file\n",
    "        \"\"\"\n",
    "        # reverse order for right YAML formatting\n",
    "        class_names = {v: k for k, v in self.class_mapping.items()}\n",
    "        \n",
    "        yaml_content = {\n",
    "            'path': self.output_dir,\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'test': 'images/test',\n",
    "            'names': class_names\n",
    "        }\n",
    "        \n",
    "        yaml_path = os.path.join(self.output_dir, 'roof_materials.yaml')\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "        \n",
    "        return yaml_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22b1089d-b4be-430f-b953-44094e28df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO dataset created at datasets/sample_dataset\n",
      "Train patches: 11\n",
      "Validation patches: 2\n",
      "Test patches: 3\n",
      "Dataset YAML created at datasets/sample_dataset/roof_materials.yaml\n"
     ]
    }
   ],
   "source": [
    "geojson_path = 'sample_buildings.geojson'\n",
    "raster_path = '61796764800b10000509eda2.tif'\n",
    "output_dir = 'datasets/sample_dataset'\n",
    "\n",
    "converter = RoofMaterialDatasetConverter(\n",
    "    geojson_path, \n",
    "    raster_path, \n",
    "    output_dir,\n",
    "    patch_min_buildings=3\n",
    ")\n",
    "\n",
    "dataset_splits = converter.generate_patches(\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "yaml_path = converter.create_dataset_yaml()\n",
    "\n",
    "print(f\"YOLO dataset created at {output_dir}\")\n",
    "print(f\"Train patches: {len(dataset_splits['train'])}\")\n",
    "print(f\"Validation patches: {len(dataset_splits['val'])}\")\n",
    "print(f\"Test patches: {len(dataset_splits['test'])}\")\n",
    "print(f\"Dataset YAML created at {yaml_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be99c6-5c2e-4e10-ab7e-839a81f71f6a",
   "metadata": {},
   "source": [
    "#### Step 3: Model Training\n",
    "We train a YOLOv8 segmentation model (yolo11n-seg.pt) on a custom dataset of roof materials. Training runs for up to 100 epochs. The model uses 640x640 images (or any multiple of 16 for the patch size), a batch size of 16, and leverages a GPU (device='0'). Training plots are enabled for visualizing performance metrics. Actual model results will be attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f69c6-5d46-4da7-a254-e85a90e78ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-seg.pt')\n",
    "\n",
    "\n",
    "results = model.train(\n",
    "    data=\"datasets/sample_dataset/roof_materials.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    plots=True,\n",
    "    device='0',\n",
    "    pretrained=True,\n",
    "    patience=20,\n",
    "    save_period=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85929b-a74a-4b86-85e5-bddcc7760167",
   "metadata": {},
   "source": [
    "#### Step 4: Model Inference\n",
    "We will apply the model we just trained to label other images (to be completed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763deb5-1ee9-41e9-8bb2-8e62e224b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_results = model.predict('', save=True, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f0cc9-80dc-424b-9c6c-1aed26da1837",
   "metadata": {},
   "source": [
    "#### Next Steps + Potential Improvements\n",
    "\n",
    "- Experimenting with smaller patch sizes to decrease the amount of patches with unlabelled houses\n",
    "- Applying data augmentation to balance out the class imbalance\n",
    "- Creating a pipeline that works for areas with sparse/non-grouped labels such as Nepal, Mozambique, Sri Lanka, and India. This was the initial goal but we realized data quality was subpar, so we pivoted to creating a reproducible pipeline in a data-rich area that could later be applied to other areas.\n",
    "- Elaborate more in the documentation and provide clearer step descriptions\n",
    "- Creating a pipeline that works for medium-high resolution satellite imagery\n",
    "- Evaluation and inference on nearby areas in Germany to expand available data\n",
    "- Manually validating test set data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
