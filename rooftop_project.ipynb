{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c129b17",
   "metadata": {},
   "source": [
    "#### Project Description\n",
    "\n",
    "Solar energy plays a crucial role in reducing greenhouse gas emissions and meeting rising energy demands. Information on building roof types and geometry is essential for assessing solar potential, improving energy efficiency, and supporting energy transition policies. Roof material and shape data also can inform studies on thermal efficiency, roof durability, disaster risk, heritage conservation, urban heat, and more.\n",
    "\n",
    "This study aims to develop a ready-to-use, AI-ready open dataset containing building roof types and geometry, along with a scalable pipeline for roof material classification. The dataset is created using OpenStreetMap (OSM) roof material labels and high-resolution satellite imagery obtained from [OpenAerialMap](https://map.openaerialmap.org/#/7.164459228515626,50.84562199133437,12/square/12020303222/617970f8800b10000509eda7?_k=h73n1n), originally from the Maxar [Open Data Program](https://www.maxar.com/open-data), leveraging OSM building outlines to avoid computationally expensive segmentation processes. This notebook includes the code to obtain and preprocess this data, which can be used to transform any geospatial dataset into the YOLO dataset format, in addition to training a model.\n",
    "\n",
    "To demonstrate the dataset‚Äôs applicability, a convolutional neural network (CNN) model, specifically, Ultralytics' YOLOv11, is used to classify roofs into categories such as roof tiles, tar paper, and metal, followed by an evaluation of the model‚Äôs performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44410146",
   "metadata": {},
   "source": [
    "#### Step 0: Ensure dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ee181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install pyyaml numpy geopandas matplotlib rasterio shapely opencv-python overpy ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99033c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib as plt\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from shapely.geometry import box, Polygon\n",
    "import cv2\n",
    "import overpy\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3cab1",
   "metadata": {},
   "source": [
    "#### Step 1: Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787161b-0084-481f-b14a-b481ba3445c5",
   "metadata": {},
   "source": [
    "First, we query all the roofs that have a roof:material OpenStreetMap(OSM) tag in the study area. We will be using the Overpass API, which allows us to fetch data from OSM. More information about the Overpass API query language and other examples can be found here: https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_API_by_Example.\n",
    "\n",
    "We recommend using taginfo's regional databases to get a better understanding of where OpenStreetMap Data you are looking for exists https://taginfo.geofabrik.de/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84730924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total buildings queried: 19375\n",
      "first 4 buildings: [{'id': 22376701, 'roof_material': 'roof_tiles', 'geometry': [(7.1748783, 50.8147237), (7.1749393, 50.8144985), (7.1748001, 50.8144834), (7.1747545, 50.8146516), (7.1747391, 50.8147086), (7.1748783, 50.8147237)]}, {'id': 22679422, 'roof_material': 'tar_paper', 'geometry': [(7.1582354, 50.8127516), (7.1582094, 50.8127861), (7.1577939, 50.8126591), (7.157824, 50.8126201), (7.157807, 50.8126066), (7.1578146, 50.8125957), (7.1578082, 50.8125928), (7.157812, 50.8125864), (7.1577886, 50.8125731), (7.1577803, 50.8125757), (7.1577763, 50.812571), (7.1577852, 50.812568), (7.1577767, 50.8125463), (7.1577662, 50.8125459), (7.1577669, 50.81254), (7.1577767, 50.8125404), (7.1577924, 50.8125227), (7.157785, 50.812518), (7.1577923, 50.8125136), (7.1577991, 50.8125181), (7.1578275, 50.8125085), (7.1578268, 50.8125011), (7.157838, 50.8125002), (7.1578383, 50.8125072), (7.1578711, 50.8125086), (7.157875, 50.8125035), (7.1578838, 50.8125041), (7.1578926, 50.8124932), (7.1579141, 50.8124921), (7.1579434, 50.8124528), (7.1579546, 50.8124562), (7.1580405, 50.8124825), (7.1583642, 50.8125798), (7.1583296, 50.8126257), (7.158311, 50.8126514), (7.1583992, 50.8126784), (7.1583729, 50.8127127), (7.1583512, 50.8127411), (7.1582629, 50.8127142), (7.1582354, 50.8127516)]}, {'id': 22764897, 'roof_material': 'roof_tiles', 'geometry': [(7.1533185, 50.8104461), (7.1533965, 50.8103614), (7.1534693, 50.8102824), (7.1533212, 50.810228), (7.1531705, 50.8103917), (7.1533185, 50.8104461)]}]\n"
     ]
    }
   ],
   "source": [
    "import overpy\n",
    "\n",
    "def query_osm(bbox: tuple[float, float, float, float]) -> list[dict[str, int|str|list[tuple[float, float]]]]:\n",
    "    \"\"\"\n",
    "    Queries OpenStreetMap (OSM) using Overpass API for buildings within a given bounding box\n",
    "    that have roof material data.\n",
    "\n",
    "    Args:\n",
    "        bbox (tuple[float, float, float, float]): Bounding box coordinates in the format \n",
    "            (min_latitude, min_longitude, max_latitude, max_longitude).\n",
    "\n",
    "    Returns:\n",
    "        list[dict[str, int | str | list[tuple[float, float]]]]: A list of dictionaries where each dictionary represents a building.\n",
    "            Each dictionary contains:\n",
    "            - \"id\" (int): OSM way ID.\n",
    "            - \"roof_material\" (str): Roof material type or \"unknown\" if not specified.\n",
    "            - \"geometry\" (list[tuple[float, float]]): List of (longitude, latitude) tuples \n",
    "              representing the building's outline.\n",
    "    \"\"\"\n",
    "    api = overpy.Overpass()\n",
    "    query = f\"\"\"\n",
    "[out:json][timeout:180];\n",
    "(\n",
    "way[\"building\"][\"roof:material\"]{bbox};\n",
    ");\n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "\"\"\"\n",
    "\n",
    "    response = api.query(query)\n",
    "\n",
    "    bldgs = []\n",
    "    for way in response.ways:\n",
    "        building = {\n",
    "        \"id\": way.id,\n",
    "        \"roof_material\": way.tags.get(\"roof:material\", \"unknown\"),\n",
    "        \"geometry\": [(float(node.lon), float(node.lat)) for node in way.nodes]\n",
    "        #shapely expects longitude, latitude, in addition to GeoJSONs, even though WGS894 uses latitude, longitude\n",
    "    }\n",
    "        bldgs.append(building)\n",
    "    return bldgs\n",
    "\n",
    "# change the bounding box coordinates to get data from your desired study area (min latitude, min longitude, max latitude, max longitude)\n",
    "bbox = (50.47044, 7.04552, 50.917936, 7.271421)\n",
    "# Cologne: 49.97138, 6.69497, 51.02720390596486, 6.907890818310556\n",
    "# Bonn: 50.47044, 7.04552, 50.917936, 7.271421\n",
    "# Meckenheim: 50.13682, 6.90614, 50.5464, 7.0739\n",
    "buildings_material = query_osm(bbox)\n",
    "\n",
    "print(f\"total buildings queried: {len(buildings_material)}\")\n",
    "print(f\"first 4 buildings: {buildings_material[0:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db4753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roof_material\n",
      "roof_tiles    13438\n",
      "tar_paper      5520\n",
      "metal           109\n",
      "wood             70\n",
      "eternit          49\n",
      "gravel           45\n",
      "glass            33\n",
      "grass            32\n",
      "concrete         28\n",
      "slate            21\n",
      "sheet            14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_building_material_gdf(buildings):\n",
    "    \"\"\"\n",
    "    Creates a GeoDataFrame from a list of building data, standardizes roof material labels,\n",
    "    filters out rare categories, and saves the data as GeoJSON files.\n",
    "\n",
    "    Args:\n",
    "        buildings (list[dict[str, int | str | list[tuple[float, float]]]]): A list of dictionaries representing buildings,\n",
    "            each containing:\n",
    "            - \"id\" (int): The OSM way ID.\n",
    "            - \"roof_material\" (str): The type of roof material.\n",
    "            - \"geometry\" (list[tuple[float, float]]): List of (longitude, latitude) tuples.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Filtered GeoDataFrame containing buildings with more common roof materials.\n",
    "    \"\"\"\n",
    "    geometries = [Polygon(building[\"geometry\"]) for building in buildings]\n",
    "    roof_materials = [building[\"roof_material\"] for building in buildings]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame({\"roof_material\": roof_materials}, geometry=geometries)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    # filter roof categories to ensure \n",
    "    category_counts = gdf[\"roof_material\"].value_counts()\n",
    "    keep_materials = category_counts[category_counts > 10].index.tolist()\n",
    "    gdf_filtered = gdf[gdf['roof_material'].isin(keep_materials)]\n",
    "\n",
    "    output_file = \"bonn_buildings.geojson\"\n",
    "    gdf.to_file(output_file, driver=\"GeoJSON\")\n",
    "\n",
    "    output_file_filtered = \"bonn_buildings_filtered.geojson\"\n",
    "    gdf_filtered.to_file(output_file_filtered, driver=\"GeoJSON\")\n",
    "    return gdf_filtered\n",
    "\n",
    "gdf_filtered = create_building_material_gdf(buildings_material)\n",
    "print(gdf_filtered['roof_material'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54038498",
   "metadata": {},
   "source": [
    "After saving the queried OpenStreetMap data to a GeoJSON, we manually align the data and fix incorrect labels in QGIS. For the purpose of the sample dataset demonstration, we will just use the GeoJSON that was just generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162a116-b686-46f1-ad8c-499c3c349996",
   "metadata": {},
   "source": [
    "#### Step 2: Create AI-Ready Dataset\n",
    "In this step, we present a general Python module to create a training dataset in the [Ultralytics YOLO instance segementation dataset format](https://docs.ultralytics.com/datasets/segment/) from geospatial data, saved to the notebook's directory. \n",
    "\n",
    "This dataset takes in a raster imagery file, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55dcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoofMaterialDatasetConverter:\n",
    "    def __init__(self, \n",
    "                 geojson_path: str, \n",
    "                 raster_path: str, \n",
    "                 output_dir: str, \n",
    "                 patch_size: int = 384, \n",
    "                 overlap: int = 128,\n",
    "                 patch_min_buildings: int = 3) -> None:\n",
    "\n",
    "        self.gdf = gpd.read_file(geojson_path)\n",
    "        self.raster = rasterio.open(raster_path)\n",
    "        \n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(output_dir, 'images', split), exist_ok=True)\n",
    "            os.makedirs(os.path.join(output_dir, 'labels', split), exist_ok=True)\n",
    "        \n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.patch_min_buildings = patch_min_buildings\n",
    "\n",
    "        self.class_mapping = {\n",
    "            'gabled': 0,\n",
    "            'flat': 1,\n",
    "            'hipped': 2,\n",
    "            'skillion': 3,\n",
    "            'gambrel': 4,\n",
    "            'half-hipped': 5,\n",
    "            'pyramidal': 6,\n",
    "            'mansard': 7\n",
    "        }\n",
    "        # self.class_mapping = {\n",
    "        #     'roof_tiles': 0,\n",
    "        #     'tar_paper': 1,\n",
    "        #     'metal': 2,\n",
    "        #     'concrete': 3,\n",
    "        #     'tile': 4,\n",
    "        #     'gravel': 5,\n",
    "        #     'glass': 6\n",
    "        # }\n",
    "\n",
    "    def generate_patches(self, \n",
    "                     train_ratio: float = 0.7, \n",
    "                     val_ratio: float = 0.15, \n",
    "                     random_state: int = 42) -> dict[str, list[tuple[str, str]]]:\n",
    "        \"\"\"\n",
    "        Generate image patches with corresponding roof material labels.\n",
    "        \n",
    "        Returns:\n",
    "            list of tuples: [(image_path, label_path), ...]\n",
    "        \"\"\"\n",
    "        rng = np.random.default_rng(random_state)\n",
    "\n",
    "        # collect all potential patches\n",
    "        all_patches: list[tuple[str, str]] = []\n",
    "        \n",
    "        height, width = self.raster.height, self.raster.width\n",
    "        for y in range(0, height, self.patch_size - self.overlap):\n",
    "            for x in range(0, width, self.patch_size - self.overlap):\n",
    "                window = Window(x, y, self.patch_size, self.patch_size)\n",
    "                \n",
    "                # read patch from raster\n",
    "                try:\n",
    "                    patch = self.raster.read(window=window)\n",
    "                    patch = np.transpose(patch[:3], (1, 2, 0))  # transpose to HWC\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping patch at ({x},{y}) due to error: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # check if patch contains any roof material labels\n",
    "                patch_bounds = box(\n",
    "                    self.raster.xy(y, x)[0], \n",
    "                    self.raster.xy(y, x)[1],\n",
    "                    self.raster.xy(y + self.patch_size, x + self.patch_size)[0],\n",
    "                    self.raster.xy(y + self.patch_size, x + self.patch_size)[1]\n",
    "                )\n",
    "                \n",
    "                # filter roof polygons within this patch\n",
    "                patch_roofs = self.gdf[self.gdf.intersects(patch_bounds)]\n",
    "                \n",
    "                if len(patch_roofs) >= self.patch_min_buildings:\n",
    "                    label_content = self._generate_labels(patch_roofs, patch_bounds)\n",
    "                    if label_content:\n",
    "                        all_patches.append((patch, (y, x), label_content))\n",
    "        \n",
    "        # randomly split patches\n",
    "        n_patches = len(all_patches)\n",
    "        train_size = int(n_patches * train_ratio)\n",
    "        val_size = int(n_patches * val_ratio)\n",
    "        \n",
    "        rng.shuffle(all_patches)\n",
    "        \n",
    "        train_patches = all_patches[:train_size]\n",
    "        val_patches = all_patches[train_size:train_size+val_size]\n",
    "        test_patches = all_patches[train_size+val_size:]\n",
    "        \n",
    "        split_paths = {\n",
    "            'train': [],\n",
    "            'val': [],\n",
    "            'test': []\n",
    "        }\n",
    "        \n",
    "        for split, patches in [('train', train_patches), ('val', val_patches), ('test', test_patches)]:\n",
    "            for patch, (y, x), label_content in patches:\n",
    "                patch_filename = f'patch_{y}_{x}.png'\n",
    "                \n",
    "                img_path = os.path.join(self.output_dir, 'images', split, patch_filename)\n",
    "                label_path = os.path.join(self.output_dir, 'labels', split, patch_filename.replace('.png', '.txt'))\n",
    "                \n",
    "                os.makedirs(os.path.dirname(img_path), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(label_path), exist_ok=True)\n",
    "                \n",
    "                cv2.imwrite(img_path, cv2.cvtColor(patch, cv2.COLOR_RGB2BGR))\n",
    "                \n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(label_content))\n",
    "                split_paths[split].append((img_path, label_path))\n",
    "        \n",
    "        return split_paths\n",
    "\n",
    "    def _generate_labels(self, \n",
    "                         roof_polygons: gpd.GeoDataFrame,\n",
    "                         patch_bounds: box) -> list[str]:\n",
    "        \"\"\"\n",
    "        Generate YOLO segmentation labels for roof polygons in a patch.\n",
    "        \n",
    "        Parameters:\n",
    "            roof_polygons : GeoDataFrame\n",
    "                GeoDataFrame of roof polygons in the current patch\n",
    "            patch_bounds : shapely.geometry.box\n",
    "                Bounding box of the current patch\n",
    "        \n",
    "        Returns:\n",
    "            list of label strings\n",
    "        \"\"\"\n",
    "        labels: list[str] = []\n",
    "        \n",
    "        for _, roof in roof_polygons.iterrows():\n",
    "            # only include specified roof material classes\n",
    "            class_name = roof['roof_shape']\n",
    "            if class_name not in self.class_mapping:\n",
    "                continue\n",
    "            class_index = self.class_mapping[class_name]\n",
    "            \n",
    "            # clip polygon to patch bounds\n",
    "            clipped_roof = roof.geometry.intersection(patch_bounds)\n",
    "            \n",
    "            if not clipped_roof.is_empty:\n",
    "                try:\n",
    "                    coords = np.array(clipped_roof.exterior.coords)\n",
    "                    normalized_coords = self._normalize_coordinates(coords, patch_bounds)\n",
    "                    \n",
    "                    if len(normalized_coords) >= 3:\n",
    "                        # create label string: class_index x1 y1 x2 y2 ...\n",
    "                        label = f\"{class_index} \" + \" \".join(map(str, normalized_coords.flatten()))\n",
    "                        labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing roof polygon: {e}\")\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def _normalize_coordinates(self, \n",
    "                               coords: np.ndarray, \n",
    "                               patch_bounds: box) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Normalize polygon coordinates to 0-1 range within patch.\n",
    "        \n",
    "        Parameters:\n",
    "            coords: numpy.ndarray\n",
    "                Original polygon coordinates\n",
    "            patch_bounds : shapely.geometry.box\n",
    "                Bounding box of the current patch\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray of normalized coordinates\n",
    "        \"\"\"\n",
    "        x_min, y_min = patch_bounds.bounds[0], patch_bounds.bounds[1]\n",
    "        x_max, y_max = patch_bounds.bounds[2], patch_bounds.bounds[3]\n",
    "        normalized_coords = coords.copy()\n",
    "        normalized_coords[:, 0] = (coords[:, 0] - x_min) / (x_max - x_min)\n",
    "        #normalized_coords[:, 1] = (coords[:, 1] - y_min) / (y_max - y_min)\n",
    "        normalized_coords[:, 1] = (y_max - coords[:, 1]) / (y_max - y_min)\n",
    "\n",
    "        return normalized_coords\n",
    "    \n",
    "    def create_dataset_yaml(self) -> str:\n",
    "        \"\"\"\n",
    "        Create YOLO dataset configuration YAML file.\n",
    "        \n",
    "        Returns:\n",
    "            str: Path to the created YAML file\n",
    "        \"\"\"\n",
    "        # reverse order for right YAML formatting\n",
    "        class_names = {v: k for k, v in self.class_mapping.items()}\n",
    "        \n",
    "        yaml_content = {\n",
    "            'path': self.output_dir,\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'test': 'images/test',\n",
    "            'names': class_names\n",
    "        }\n",
    "        \n",
    "        yaml_path = os.path.join(self.output_dir, 'roof_materials.yaml')\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "        \n",
    "        return yaml_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acefc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_path = 'bonn_roof_shapes_aligned.geojson'\n",
    "raster_path = '61796764800b10000509eda2.tif'\n",
    "output_dir = 'datasets/bonn_dataset_shape'\n",
    "# ran this for bonn_aligned (roof materials) small and bonn_roof_shape_aligned\n",
    "\n",
    "converter = RoofMaterialDatasetConverter(\n",
    "    geojson_path, \n",
    "    raster_path, \n",
    "    output_dir,\n",
    "    patch_min_buildings=3\n",
    ")\n",
    "\n",
    "dataset_splits = converter.generate_patches(\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "yaml_path = converter.create_dataset_yaml()\n",
    "\n",
    "print(f\"YOLO dataset created at {output_dir}\")\n",
    "print(f\"Train patches: {len(dataset_splits['train'])}\")\n",
    "print(f\"Validation patches: {len(dataset_splits['val'])}\")\n",
    "print(f\"Test patches: {len(dataset_splits['test'])}\")\n",
    "print(f\"Dataset YAML created at {yaml_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b3937-0861-4d94-93d0-bd6f26de46b5",
   "metadata": {},
   "source": [
    "#### Step 3: Model Training\n",
    "\n",
    "Next, we train the pre-trained [Ultralytics YOLOv11](https://docs.ultralytics.com/models/yolo11/) instance segmentation model on our roof material dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f5da2-c470-45e0-bc5a-6043c478ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.105 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.100 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11s-seg.pt, data=datasets/bonn_dataset_shape/roof_materials.yaml, epochs=100, time=None, patience=20, batch=16, imgsz=320, save=True, save_period=10, cache=False, device=0, workers=8, project=None, name=run_5_shape, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/roofmap_project/runs/segment/run_5_shape\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1   1477000  ultralytics.nn.modules.head.Segment          [8, 32, 128, [128, 256, 512]] \n",
      "YOLO11s-seg summary: 203 layers, 10,085,384 parameters, 10,085,368 gradients, 35.6 GFLOPs\n",
      "\n",
      "Transferred 555/561 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ubuntu/roofmap_project/datasets/bonn_dataset_shape/labels/train.cache... 5556 images, 0 ba\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/ubuntu/roofmap_project/datasets/bonn_dataset_shape/images/train/patch_5376_60160.png: ignoring corrupt image/label: image size (384, 3) <10 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/roofmap_project/datasets/bonn_dataset_shape/labels/val.cache... 1190 images, 0 backgr\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/ubuntu/roofmap_project/runs/segment/run_5_shape/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/ubuntu/roofmap_project/runs/segment/run_5_shape\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      7.46G      2.199      3.537      2.321        1.4         91        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792       0.71     0.0797     0.0612     0.0299      0.705     0.0752     0.0556     0.0231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      7.46G      1.874      3.101      1.827      1.205        140        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.605      0.136     0.0809     0.0405      0.603      0.128     0.0737     0.0315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      7.46G      1.842      3.042      1.775      1.186         80        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.121      0.161     0.0819     0.0419       0.24      0.146     0.0731     0.0306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      7.46G      1.793      2.959      1.735      1.166         92        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.466      0.155     0.0792     0.0386      0.461      0.142     0.0687     0.0276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      7.46G      1.747      2.903      1.709      1.152         44        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.503      0.179      0.102     0.0562      0.504      0.166     0.0948     0.0433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      7.46G      1.726      2.851      1.661      1.137        144        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792       0.49      0.163      0.107     0.0567      0.489      0.156     0.0984      0.043\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      7.46G      1.697      2.805      1.636      1.128        108        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.355      0.189      0.117     0.0647      0.352      0.179      0.109     0.0524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      7.46G      1.677      2.776      1.626      1.121         27        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.326      0.205      0.118     0.0644      0.314      0.194      0.109     0.0502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      7.46G      1.655      2.735      1.587      1.109        119        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792       0.28      0.203      0.129      0.074      0.268      0.202      0.121     0.0585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      7.46G      1.637      2.716      1.571      1.104         91        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.138      0.228      0.124     0.0688      0.129      0.214      0.114     0.0527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      7.46G      1.619      2.688      1.547      1.097         66        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.184      0.232      0.135     0.0766      0.181      0.221      0.125     0.0583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      7.46G      1.614      2.663      1.548      1.094         78        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792       0.15      0.237      0.137     0.0766      0.142      0.228      0.127     0.0592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      7.46G      1.593      2.659      1.533       1.09         52        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.287      0.204      0.129     0.0732      0.308       0.18      0.119     0.0573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      7.46G      1.587      2.631      1.526      1.082        269        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.164       0.21      0.135      0.078      0.158      0.201      0.124     0.0598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      7.46G      1.566      2.604      1.503      1.078         81        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.406      0.234      0.144     0.0839        0.4      0.224      0.134     0.0655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      7.46G      1.562       2.59      1.504      1.075        143        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.185      0.263      0.145     0.0834      0.179      0.244      0.137     0.0653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      7.46G      1.553      2.565      1.499      1.075        114        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.298      0.229      0.148     0.0848       0.29      0.218      0.138      0.066\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      7.46G      1.544      2.564      1.482      1.073        142        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.201      0.258      0.151     0.0891       0.18      0.234      0.141     0.0691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      7.46G      1.536      2.553       1.48      1.069         65        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792       0.33      0.241      0.148      0.087      0.327       0.23      0.137     0.0695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      7.46G      1.528      2.524      1.477      1.068         55        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.238      0.254      0.161      0.097      0.235       0.24       0.15     0.0746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      7.46G      1.517      2.521       1.45      1.059         36        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.243      0.231      0.162     0.0957       0.24      0.218      0.151     0.0751\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      7.46G      1.516       2.53      1.444       1.06         68        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.224      0.278      0.174      0.104      0.218      0.267      0.163     0.0816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      7.46G       1.51      2.501      1.439      1.055         72        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.252      0.274      0.172      0.102      0.241      0.261       0.16       0.08\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      7.46G      1.505      2.493      1.427      1.054         56        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.389      0.264       0.18      0.107       0.38      0.251      0.168     0.0838\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      7.46G      1.495      2.483      1.414       1.05        126        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.221       0.25       0.17      0.101      0.208      0.239      0.158     0.0766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      7.46G      1.488      2.464      1.425      1.053         95        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.228      0.266       0.18      0.108      0.226      0.249      0.168     0.0823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      7.46G       1.48      2.457      1.405      1.044        104        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.229      0.262      0.174      0.105      0.221      0.247      0.161     0.0817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      7.46G      1.484      2.463      1.413      1.046         88        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792        0.2      0.263      0.171      0.102      0.192       0.25       0.16     0.0797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      7.46G      1.473       2.45      1.406      1.044        115        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1190      21792      0.272      0.263      0.186      0.114      0.266       0.25      0.173     0.0884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      7.46G      1.458      2.419      1.386      1.034        444        320:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 207/3"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolo11s-seg.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data='datasets/bonn_dataset_shape/roof_materials.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=320,\n",
    "    batch=16,\n",
    "    plots=True,\n",
    "    device='0',\n",
    "    pretrained=True,\n",
    "    patience=20,\n",
    "    save_period=10,\n",
    "    name=f'run_5_shape'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27633de-47c6-4d73-80d3-d48313ee75f4",
   "metadata": {},
   "source": [
    "#### Next Steps + Potential Improvements\n",
    "\n",
    "- Experimenting with smaller patch sizes to decrease the amount of patches with unlabelled houses\n",
    "- Training using a custom model architecture\n",
    "- Applying data augmentation to balance out the \n",
    "- Creating a pipeline that works for areas with sparse/non-grouped labels such as Nepal, Mozambique, Sri Lanka, and India. This was the initial goal but we realized data quality was subpar, so we pivoted to creating a reproducible pipeline in a data-rich area that could later be applied to other areas.\n",
    "- Creating a pipeline that works for medium-high resolution satellite imagery\n",
    "- Provide model checkpoints\n",
    "- Evaluation and inference on nearby areas in Germany to expand available data\n",
    "- Manually validating test set data\n",
    "- Create roof shape dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
